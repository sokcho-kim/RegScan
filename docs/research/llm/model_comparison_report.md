# RegScan LLM 모델 비교 보고서

**작성일:** 2026-02-06
**작성자:** 소작농 2호
**프로젝트:** RegScan - 글로벌 의약품 규제 모니터링 시스템
**문서 목적:** 프로젝트 전반에 산재된 LLM 모델 비교 데이터를 통합 정리

---

## 1. 테스트 개요

### 1.1 비교 목적

RegScan 프로젝트는 두 가지 LLM 활용 영역에서 모델 비교를 수행하였다:

1. **브리핑 리포트 생성** (`regscan/report/llm_generator.py`): 글로벌 승인 의약품의 국내 도입 전망 및 메드클레임 시사점을 자동 생성하는 기능. 약물 데이터(FDA/EMA/MFDS/HIRA/CRIS)를 입력받아 JSON 구조의 브리핑 리포트를 출력한다.

2. **큐레이션(규제문서 요약 및 영향도 분석)** (`docs/exist_module/llm-curation-model-prompt.md`): 입법/행정예고 문서를 읽고 핵심 변경사항, 영향 대상, 보험심사 체크포인트 등을 구조화된 형식으로 요약하는 기능.

### 1.2 비교 대상 모델

| 영역 | 비교 모델 | 비교 항목 |
|------|-----------|-----------|
| 브리핑 리포트 | gpt-4o-mini vs gpt-4o | 응답시간, 품질, 비용 |
| 큐레이션 (비용) | gpt-5-nano vs gpt-5.1 vs gpt-5.2 | API 비용, 토큰 사용량 |
| 큐레이션 (품질) | gpt-5.1 vs gpt-5-nano vs gpt-5.2 | 출력 품질, 구조화 정도 |
| 지원 모델 목록 | OpenAI: gpt-4o-mini, gpt-4o, gpt-4-turbo, o1-mini | - |
| 지원 모델 목록 | Anthropic: claude-sonnet-4-20250514, claude-3-haiku | - |

### 1.3 테스트 약물/문서

**브리핑 리포트 테스트:**
- pembrolizumab (급여 고가 항암제, 상한가 약 210만원)
- ELRANATAMAB (국내 미허가 + 임상 진행 중)

**큐레이션 테스트:**
- TEST 1: 국민건강보험법 시행규칙 일부개정령(안) - 영향도 A(직접영향)
- TEST 2: 월별 건강보험료액의 상한과 하한에 관한 고시 - 영향도 B(간접영향)

---

## 2. 모델별 성능 비교표

### 2.1 브리핑 리포트 생성 모델 비교 (gpt-4o-mini vs gpt-4o)

> 출처: `docs/worklog/2026-02-04.md` 섹션 17, `scripts/compare_models.py`

| 항목 | gpt-4o-mini | gpt-4o | 비고 |
|------|-------------|--------|------|
| **응답시간** | 6~10초 | 8~10초 | gpt-4o-mini가 약간 빠름 |
| **출력 품질** | 좋음 | 좋음 (문장 자연스러움) | gpt-4o가 문장 자연스러움에서 우위 |
| **비용 (입력)** | $0.15/1M tokens | $2.50/1M tokens | gpt-4o-mini가 약 17배 저렴 |
| **비용 (출력)** | $0.60/1M tokens | $10.00/1M tokens | gpt-4o-mini가 약 17배 저렴 |
| **프롬프트 전략** | 간결한 지시, JSON 출력 강조 | 상세한 CoT + Few-Shot | 모델별 최적화 적용 |
| **개선 전 문제** | placeholder 출력 | - | "핵심 포인트 1 (글로벌 승인 현황)" 등 |
| **개선 후 결과** | 구체적 내용 출력 | 구체적 내용 출력 | "FDA 승인 2025년, 본인부담 약 63만원(30%)" |
| **접근 권한** | 사용 가능 | 사용 가능 | o1-mini는 접근 권한 필요 |

### 2.2 큐레이션 모델 비용 비교 (gpt-5 시리즈)

> 출처: `docs/exist_module/llm-curation-model-prompt.md`

#### 2.2.1 조합별 비용 비교 (31건 문서 큐레이션 기준)

| 구성 | 총 비용 | 원화 환산 | 총 토큰 | 호출 수 |
|------|---------|-----------|---------|---------|
| **gpt-5-nano 단독** (filtering + curation) | **$0.081** | **약 120원** | 407,304 | 31 |
| gpt-5-nano (filtering) + gpt-5.1 (curation) | $0.470 | 약 700원 | 258,650 | 31 |
| gpt-5.1 (filtering) + gpt-5.1 (curation) | $0.537 | 약 800원 | 247,330 | 31 |
| gpt-5-nano (filtering) + gpt-5.1 (curation) [재실험] | $0.467 | 약 690원 | 265,983 | 31 |
| gpt-5-nano (filtering) + gpt-5.2 (curation) | $0.530 | 약 780원 | 245,853 | 29 |

#### 2.2.2 컴포넌트별 상세 비용

| 컴포넌트 | 모델 | 호출 수 | 프롬프트 토큰 | 완성 토큰 | 비용 |
|----------|------|---------|--------------|-----------|------|
| LLM_curation | gpt-5-nano | 31 | 235,259 | 172,045 | $0.081 |
| LLM_filtering | gpt-5-nano | 3 | 36,033 | 13,996 | $0.007 |
| LLM_curation | gpt-5.1 | 28 | 185,558 | 23,063 | $0.463 |
| LLM_filtering | gpt-5.1 | 3 | 36,033 | 3,039 | $0.075 |
| LLM_curation | gpt-5.2 | 26 | 171,948 | 15,668 | $0.520 |

**핵심 관찰:**
- gpt-5-nano는 완성 토큰이 172,045개로 gpt-5.1(23,063개) 대비 약 7.5배 많다. 이는 gpt-5-nano가 더 많은 토큰을 생성하지만, 단가가 극히 저렴하여 총 비용은 오히려 가장 낮다.
- gpt-5.1과 gpt-5.2의 비용 차이는 미미하다 ($0.463 vs $0.520).
- filtering 단계에서 gpt-5-nano를 사용하면 gpt-5.1 대비 약 10배 저렴하다 ($0.007 vs $0.075).

### 2.3 모델 비용 요약표

| 모델 | 1회 큐레이션 비용 (31건 기준) | 건당 평균 비용 | 토큰 효율성 |
|------|------------------------------|----------------|-------------|
| gpt-5-nano (단독) | $0.081 (약 120원) | $0.003/건 (약 4원) | 토큰 많이 생성하나 단가 극저 |
| gpt-5-nano + gpt-5.1 | $0.470 (약 700원) | $0.015/건 (약 23원) | 필터링 저가 + 큐레이션 고품질 |
| gpt-5.1 단독 | $0.537 (약 800원) | $0.017/건 (약 26원) | 고품질, 높은 비용 |
| gpt-5-nano + gpt-5.2 | $0.530 (약 780원) | $0.018/건 (약 27원) | 최고 품질, 최고 비용 |

---

## 3. 프롬프트 최적화 전략

> 출처: `regscan/report/prompts.py`

### 3.1 공통 시스템 프롬프트

모든 모델에 공통으로 적용되는 시스템 프롬프트에는 다음이 포함된다:

- **역할 설정**: 의약품 규제 전문 기자 + 건강보험 전문가
- **전문 분야**: FDA/EMA/MFDS 승인 절차, HIRA 급여 심사, 희귀의약품/항암제/바이오의약품 급여 정책, 메드클레임 실무
- **작성 원칙**: 객관적 사실만 기술, 전문 용어 사용, 구체적 수치 포함, 한국어 작성(약물명/기관명 영문 유지)
- **도메인 지식 주입**:
  - 일반 급여: 본인부담 30%
  - 희귀질환 산정특례: 본인부담 10%
  - 암환자 산정특례: 본인부담 5%
  - 고가약제(100만원 이상): 사전심사 대상 가능
  - 비급여: 전액 환자부담, 실손보험 청구 가능

### 3.2 모델별 프롬프트 최적화 (`get_optimized_prompt()`)

| 모델 | 프롬프트 전략 | 설명 |
|------|---------------|------|
| **gpt-4o-mini** / gpt-3.5 | 간결한 지시 + JSON 출력 강조 | 토큰 효율성 극대화. 최소한의 지시로 JSON만 출력하도록 유도. CoT/Few-Shot 생략. |
| **gpt-4o** / gpt-5 시리즈 | 상세한 CoT + Few-Shot | 4단계 Chain-of-Thought(글로벌 현황 -> 국내 현황 -> 메드클레임 시사점 -> 핵심 메시지 도출) + 2개 Few-Shot 예시(급여 약물 + 미허가 약물) |
| **Claude** 시리즈 | CoT + Few-Shot (GPT-4o와 동일) | 현재 별도 최적화 없이 GPT-4o와 동일한 프롬프트 사용 |

### 3.3 프롬프트 엔지니어링 기법 상세

**적용된 기법 (Prompt-Engineering-Guide 참고):**

1. **Few-Shot Learning**: 2개의 예시 제공
   - 예시 1: 급여 적용 고가 항암제 (PEMBROLIZUMAB) - 상한가 210만원, 급여 적용 시나리오
   - 예시 2: 국내 미허가 신약 (ELRANATAMAB) - MFDS 미허가, 임상 참여 시나리오

2. **Chain-of-Thought (4단계)**:
   - 1단계: 글로벌 승인 현황 파악 (FDA/EMA 승인 여부, Breakthrough/Orphan/PRIME 지정)
   - 2단계: 국내 현황 파악 (MFDS 허가, HIRA 급여 상태, CRIS 임상)
   - 3단계: 메드클레임 시사점 분석 (본인부담률, 고가약제, 산정특례)
   - 4단계: 핵심 메시지 도출 (4가지 핵심 포인트)

3. **도메인 지식 주입**: 급여 정책 수치 (30%/10%/5%), 고가약제 기준 (100만원)

### 3.4 개선 효과

| 항목 | Before (프롬프트 최적화 전) | After (프롬프트 최적화 후) |
|------|---------------------------|--------------------------|
| key_points | `"핵심 포인트 1 (글로벌 승인 현황)"` (placeholder) | `"FDA 승인 2025년, 본인부담 약 63만원(30%)"` (구체적) |
| medclaim_section | 일반적 내용 | 상한가, 본인부담률, 산정특례 등 구체적 수치 포함 |
| 구조 | 불안정한 JSON 파싱 | 안정적 JSON 구조 출력 |

---

## 4. 품질 비교 예시

### 4.1 브리핑 리포트 실제 출력 비교 (SELADELPAR LYSINE)

> 출처: `output/briefings/seladelpar_lysine.md` (gpt-4o-mini로 생성, 2026-02-05)

```
제목: SELADELPAR LYSINE, FDA 승인 - 국내 미허가
부제: 희귀의약품으로 EMA 승인 예정

핵심 요약:
1. FDA에서 2024년 8월 승인, EMA는 2025년 5월 예정
2. MFDS 미허가 상태로 국내 처방 불가
3. 현재 HIRA 급여 심사 중단 상태
4. 희귀의약품으로 글로벌 관심과 기대 상승

메드클레임 시사점:
국내에서 MFDS 미허가 상태로 급여 적용이 불가하여 비급여로 취급될 가능성이 높습니다.
비급여 상태에서는 환자가 전액 부담해야 하며, 실손보험 청구는 가능합니다.
```

**평가:** gpt-4o-mini로 생성된 출력이지만, 프롬프트 최적화 후 구체적인 승인 날짜, 급여 상태, 메드클레임 시사점을 잘 포착하고 있다. 다만 "급여 심사 중단 상태"라는 표현은 실제 데이터(HIRA status: not_found)를 다소 자의적으로 해석한 부분이다.

### 4.2 큐레이션 품질 비교 (국민건강보험법 시행규칙 일부개정령)

> 출처: `docs/exist_module/llm-curation-model-prompt.md` TEST 1

#### gpt-5.1 출력 특징:
- **제목**: "중증 소아/청소년 요양비/장애인보조기기 급여 확대 및 간호인력 신고서식 정비"
- **한 줄 요약**: 구체적 법조문 번호 인용 (시행규칙 제23조, 별표 7 등)
- **비교표**: 5개 항목, 개정 전/후 상세 기술 (법조문/별지서식 번호까지 명시)
- **개정 배경**: 4개 항목으로 구분, 명확한 인과관계 서술
- **Q&A**: 법적 근거를 정확히 인용하여 답변
- **분량**: 약 2,500자

#### gpt-5-nano 출력 특징:
- **제목**: "국민건강보험법 시행규칙 일부개정령(안) 입법예고 이슈 해설"
- **한 줄 요약**: 4대 제도개편을 나열하는 방식 (구체적 법조문 번호 부분 인용)
- **비교표**: 4개 항목, 개정 전/후 기술 (gpt-5.1보다 간략)
- **개정 배경**: 3개 항목으로 구분, 일반적 서술
- **Q&A**: 기본적 사실 답변 (법적 근거 부분 인용)
- **관련 문서**: 본문에 언급되지 않은 관련 보도자료 2건 추가 (환각 가능성)
- **분량**: 약 1,800자

#### 품질 비교 요약:

| 항목 | gpt-5.1 | gpt-5-nano |
|------|---------|------------|
| 법조문 정확도 | 높음 (조항/서식 번호 정확 인용) | 중간 (일부 인용, 일부 누락) |
| 구조화 수준 | 높음 (5개 항목 상세 비교표) | 중간 (4개 항목 간략 비교표) |
| 환각(hallucination) | 거의 없음 | 관련 보도자료 2건 추가 (검증 필요) |
| 실무 유용성 | 높음 (체크포인트 구체적) | 중간 (체크포인트 일반적) |
| 비용 | $0.463/28건 | $0.081/31건 |

### 4.3 실제 운영 브리핑 리포트 (핫이슈 5건 일괄 생성)

> 출처: `output/briefings/hot_issues_2026-02-05.md` (2026-02-05 생성)

5건의 핫이슈 약물에 대한 브리핑이 gpt-4o-mini로 일괄 생성되었다:

| 약물 | Hot Issue Score | 핵심 내용 | 품질 평가 |
|------|----------------|-----------|-----------|
| POLATUZUMAB VEDOTIN | 75 | FDA/EMA/MFDS 3개국 승인, HIRA 비급여 | 승인 날짜/기관명 정확 |
| ZOLBETUXIMAB-CLZB | 70 | 3개국 승인, HIRA 미등재 | 정확 |
| MIRVETUXIMAB SORAVTANSINE | 70 | FDA/EMA/MFDS 승인, 비급여 | 정확 |
| TALQUETAMAB-TGVS | 70 | EMA/MFDS 승인, FDA 예정, 비급여 | 정확 |
| SELADELPAR LYSINE | 65 | FDA 승인, MFDS 미허가 | 정확 |

---

## 5. 비용 분석

### 5.1 브리핑 리포트 생성 비용 (API 호출당)

브리핑 리포트 1건 생성 시 약 2,000 토큰 max_tokens 설정 기준:

| 모델 | 예상 입력 토큰 | 예상 출력 토큰 | 예상 호출당 비용 | 비고 |
|------|---------------|---------------|-----------------|------|
| gpt-4o-mini | ~1,500 | ~800 | **약 $0.0007** (약 1원) | 기본 모델 (현재 운영) |
| gpt-4o | ~1,500 | ~800 | **약 $0.012** (약 17원) | 고품질 필요 시 |
| gpt-4-turbo | ~1,500 | ~800 | 약 $0.024 | 미테스트 |
| claude-sonnet-4-20250514 | ~1,500 | ~800 | 약 $0.012 | 미테스트 |

### 5.2 큐레이션 비용 (1회 실행 = 31건 문서 기준)

| 구성 | 비용 | 원화 환산 |
|------|------|-----------|
| gpt-5-nano 단독 | $0.081 | 약 120원 |
| gpt-5-nano (filter) + gpt-5.1 (curate) | $0.467~0.470 | 약 690~700원 |
| gpt-5.1 단독 | $0.537 | 약 800원 |
| gpt-5-nano (filter) + gpt-5.2 (curate) | $0.530 | 약 780원 |

### 5.3 월간 예상 운영 비용

**시나리오: 일간 모니터링 운영 (월 22영업일 기준)**

| 용도 | 일간 호출 | 모델 | 일간 비용 | **월간 비용** |
|------|----------|------|----------|-------------|
| 브리핑 리포트 (핫이슈 5~10건) | 10건 | gpt-4o-mini | $0.007 | **$0.15 (약 220원)** |
| 브리핑 리포트 (핫이슈 5~10건) | 10건 | gpt-4o | $0.12 | **$2.64 (약 3,900원)** |
| 큐레이션 (일간 신규 문서) | 31건 | gpt-5-nano 단독 | $0.081 | **$1.78 (약 2,600원)** |
| 큐레이션 (일간 신규 문서) | 31건 | gpt-5-nano + gpt-5.1 | $0.470 | **$10.34 (약 15,300원)** |

**월간 총 비용 시나리오:**

| 시나리오 | 브리핑 모델 | 큐레이션 모델 | **월간 합계** |
|----------|-----------|-------------|-------------|
| **경제형** | gpt-4o-mini | gpt-5-nano 단독 | **$1.93 (약 2,800원)** |
| **균형형** | gpt-4o-mini | gpt-5-nano + gpt-5.1 | **$10.49 (약 15,500원)** |
| **고품질형** | gpt-4o | gpt-5-nano + gpt-5.1 | **$13.0 (약 19,200원)** |
| **최고품질형** | gpt-4o | gpt-5.1 단독 | **$14.5 (약 21,400원)** |

> 참고: GCP Cloud Run 서버 비용 약 $10/월 별도 (`docs/proposal/gcp_cloud_run_spec.md`)

---

## 6. 결론 및 권장사항

### 6.1 브리핑 리포트 생성 모델

**권장: gpt-4o-mini (현행 유지)**

- gpt-4o-mini와 gpt-4o의 품질 차이가 미미한 반면, 비용은 약 17배 차이가 난다.
- 프롬프트 최적화(Few-Shot + CoT + 도메인 지식 주입) 적용 후 gpt-4o-mini의 출력 품질이 크게 향상되었다.
- 응답시간도 gpt-4o-mini가 6~10초로 gpt-4o(8~10초)보다 빠르다.
- 실제 운영 출력(핫이슈 5건 일괄 브리핑)에서 승인 날짜, 기관명, 급여 상태 등 팩트가 정확하게 출력되고 있다.
- gpt-4o는 "문장 자연스러움"에서 약간의 우위가 있으나, 비용 대비 실무적 이점이 크지 않다.

### 6.2 큐레이션 모델

**권장: gpt-5-nano (필터링) + gpt-5.1 (큐레이션) 조합**

- gpt-5-nano 단독 ($0.081)은 비용이 극히 저렴하나, 환각(hallucination) 위험이 있고 법조문 인용 정확도가 떨어진다.
- gpt-5.1 단독 ($0.537)은 필터링 단계에서 불필요하게 비싼 모델을 사용하는 것이다.
- **gpt-5-nano (필터링) + gpt-5.1 (큐레이션) 조합 ($0.467~0.470)**이 비용 대비 품질의 최적점이다:
  - 필터링은 단순 분류 작업이므로 gpt-5-nano로 충분 ($0.007~0.010)
  - 큐레이션은 법조문 정확도와 구조화가 중요하므로 gpt-5.1이 적합 ($0.457~0.463)
- gpt-5.2는 gpt-5.1 대비 비용이 $0.06 더 비싸지만 ($0.530 vs $0.470), 뚜렷한 품질 향상이 확인되지 않았다.

### 6.3 향후 검토 사항

1. **Claude 모델 테스트**: `claude-sonnet-4-20250514`, `claude-3-haiku`가 지원 모델로 등록되어 있으나 아직 실제 비교 테스트가 수행되지 않았다. XML 태그 기반 프롬프트 최적화를 통해 품질 향상 가능성이 있다.

2. **o1-mini 테스트**: 접근 권한 확보 후 추론 집약적 작업(영향도 판단, 복잡한 급여 분석)에서의 성능을 테스트할 필요가 있다.

3. **gpt-4o-mini 프롬프트 한계**: 현재 gpt-4o-mini용 프롬프트는 CoT/Few-Shot을 생략하고 간결한 JSON 지시만 사용한다. 토큰 비용이 낮으므로 일부 Few-Shot을 추가하여 품질을 더 높일 여지가 있다.

4. **환각 모니터링**: gpt-5-nano의 큐레이션에서 관련 보도자료를 자의적으로 추가하는 현상이 관찰되었다. 운영 시 팩트체크 파이프라인 또는 사후 검증 단계 도입을 고려해야 한다.

5. **비용 모니터링**: 월간 비용이 최대 약 $15 수준으로 매우 경제적이나, 처리 문서 수 증가 시 선형적으로 비용이 증가하므로 사용량 모니터링이 필요하다.

---

## 부록: 참조 파일 목록

| 파일 | 내용 |
|------|------|
| `scripts/compare_models.py` | 브리핑 리포트 모델 비교 스크립트 (gpt-4o-mini vs gpt-4o) |
| `docs/exist_module/llm-curation-model-prompt.md` | 큐레이션 모델 비용/품질 비교 원본 데이터 |
| `docs/worklog/2026-02-04.md` (섹션 17) | 프롬프트 엔지니어링 개선 및 모델 비교 테스트 결과 |
| `regscan/report/llm_generator.py` | LLM 브리핑 생성기 (지원 모델, compare_models() 함수) |
| `regscan/report/prompts.py` | 모델별 프롬프트 최적화 전략 (get_optimized_prompt()) |
| `output/briefings/hot_issues_2026-02-05.md` | 실제 운영 브리핑 출력 예시 (핫이슈 5건) |
| `output/briefings/seladelpar_lysine.md` | 개별 약물 브리핑 출력 예시 |
| `output/briefings/polatuzumab_vedotin-piiq.md` | 개별 약물 브리핑 출력 예시 |
